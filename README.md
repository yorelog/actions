# CUDA 12.1.1 ç”Ÿäº§æ„å»ºç¯å¢ƒ

ä¸“ä¸º PyTorch å’Œ vLLM ç¼–è¯‘ä¼˜åŒ–çš„ CUDA 12.1.1 ç”Ÿäº§ç¯å¢ƒã€‚

## æ”¯æŒçš„ GPU

- RTX 3090Ti (Compute Capability 8.6)
- A100 (Compute Capability 8.0) 
- A800 (Compute Capability 8.0)
- H20 (Compute Capability 8.9)

## æ ¸å¿ƒç‰¹æ€§

- ğŸš€ **CUDA 12.1.1**: æœ€æ–°CUDAç‰ˆæœ¬æ”¯æŒ
- ğŸ **Python 3.12**: ä½¿ç”¨uvç®¡ç†çš„æœ€æ–°Pythonç¯å¢ƒ
- âš¡ **å¤šé˜¶æ®µæ„å»º**: ä¼˜åŒ–çš„Dockeræ„å»ºæµç¨‹
- ğŸ¯ **GPUä¼˜åŒ–**: é’ˆå¯¹ç‰¹å®šGPUæ¶æ„ä¼˜åŒ–ç¼–è¯‘
- ğŸ“¦ **è‡ªåŠ¨åŒ–æ„å»º**: GitHub Actionsè‡ªåŠ¨æ„å»ºå’Œæ¨é€

## ä½¿ç”¨æ–¹æ³•

### æ‹‰å–åŸºç¡€é•œåƒ

```bash
docker pull registry.cn-beijing.aliyuncs.com/yoce/cuda:cu121-build-prod
```

### ç¼–è¯‘ PyTorch

```bash
docker run --gpus all --rm \
  -v $(pwd)/output:/output \
  registry.cn-beijing.aliyuncs.com/yoce/cuda:cu121-build-prod \
  /scripts/build_optimized.sh pytorch 2.8.0
```

### ç¼–è¯‘ vLLM

```bash
docker run --gpus all --rm \
  -v $(pwd)/output:/output \
  registry.cn-beijing.aliyuncs.com/yoce/cuda:cu121-build-prod \
  /scripts/build_optimized.sh vllm 0.10.0
```

## GitHub Actions

é€šè¿‡ GitHub Actions è‡ªåŠ¨æ„å»ºï¼š

1. **æ„å»ºåŸºç¡€é•œåƒ**: æ¨é€ä»£ç æ—¶è‡ªåŠ¨æ„å»ºå¹¶æ¨é€åˆ°é˜¿é‡Œäº‘é•œåƒä»“åº“
2. **æ„å»º PyTorch**: æ‰‹åŠ¨è§¦å‘æŒ‡å®šç‰ˆæœ¬çš„ PyTorch ç¼–è¯‘
3. **æ„å»º vLLM**: æ‰‹åŠ¨è§¦å‘æŒ‡å®šç‰ˆæœ¬çš„ vLLM ç¼–è¯‘

## ç¯å¢ƒè¦æ±‚

- Docker with GPU support
- NVIDIA Driver >= 470
- è‡ªæ‰˜ç®¡ GitHub Runner (ç”¨äºGPUæ„å»º)

## é˜¿é‡Œäº‘é•œåƒä»“åº“

- åŸºç¡€æ„å»ºé•œåƒ: `registry.cn-beijing.aliyuncs.com/yoce/cuda:cu121-build`
- ç”Ÿäº§é•œåƒ: `registry.cn-beijing.aliyuncs.com/yoce/cuda:cu121-build-prod`

## License

MIT License