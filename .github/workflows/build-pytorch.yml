name: Build PyTorch 2.8.0 for CUDA 12.1

on:
  workflow_dispatch:
    inputs:
      pytorch_version:
        description: 'PyTorch版本'
        required: true
        default: '2.8.0'
        type: string
      gpu_arch:
        description: 'CUDA架构'
        required: true
        default: '8.0;8.6;8.9'
        type: string
  push:
    tags:
      - 'pytorch-*'
  schedule:
    # 每周日UTC时间04:00运行
    - cron: '0 4 * * 0'

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}/cu121-builder

jobs:
  build-pytorch:
    runs-on: self-hosted
    # 需要支持GPU的runner
    # runs-on: [self-hosted, gpu]
    
    permissions:
      contents: read
      packages: write
    
    strategy:
      matrix:
        include:
          - gpu_type: "A100"
            cuda_arch: "8.0"
          - gpu_type: "RTX3090Ti"
            cuda_arch: "8.6"
          - gpu_type: "H20"
            cuda_arch: "8.9"
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3
    
    - name: Log in to Container Registry
      uses: docker/login-action@v3
      with:
        registry: ${{ env.REGISTRY }}
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}
    
    - name: Extract metadata
      id: meta
      uses: docker/metadata-action@v5
      with:
        images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}
        tags: |
          type=ref,event=branch
          type=ref,event=pr
          type=semver,pattern={{version}}
          type=sha
    
    - name: Build Docker image
      uses: docker/build-push-action@v5
      with:
        context: .
        push: false
        tags: cu121-builder:latest
        cache-from: type=gha
        cache-to: type=gha,mode=max
        platforms: linux/amd64
    
    - name: Check GPU availability
      run: |
        docker run --gpus all --rm cu121-builder:latest nvidia-smi || echo "GPU not available in CI"
    
    - name: Create output directory
      run: mkdir -p output
    
    - name: Build PyTorch ${{ inputs.pytorch_version || '2.8.0' }}
      run: |
        # 设置构建参数
        PYTORCH_VERSION="${{ inputs.pytorch_version || '2.8.0' }}"
        CUDA_ARCH="${{ inputs.gpu_arch || '8.0;8.6;8.9' }}"
        
        echo "Building PyTorch version: $PYTORCH_VERSION"
        echo "CUDA architectures: $CUDA_ARCH"
        
        # 运行构建
        docker run --gpus all --rm \
          -v $(pwd)/output:/output \
          -v $(pwd)/workspace:/workspace \
          -e TORCH_CUDA_ARCH_LIST="$CUDA_ARCH" \
          -e CUDA_ARCH_LIST="$CUDA_ARCH" \
          cu121-builder:latest \
          /scripts/build_optimized.sh pytorch $PYTORCH_VERSION
      timeout-minutes: 480  # 8小时超时
    
    - name: List built files
      run: |
        echo "Built PyTorch files:"
        ls -la output/
        
        # 检查wheel文件
        if ls output/torch-*.whl 1> /dev/null 2>&1; then
          echo "✅ PyTorch wheel文件构建成功"
          for file in output/torch-*.whl; do
            echo "  - $(basename $file) ($(du -h $file | cut -f1))"
          done
        else
          echo "❌ 未找到PyTorch wheel文件"
          exit 1
        fi
    
    - name: Test PyTorch wheel
      run: |
        # 测试安装和基本功能
        docker run --gpus all --rm \
          -v $(pwd)/output:/wheels \
          cu121-builder:latest bash -c "
            pip install /wheels/torch-*.whl && \
            python3 -c 'import torch; print(f\"PyTorch version: {torch.__version__}\"); print(f\"CUDA available: {torch.cuda.is_available()}\"); print(f\"CUDA version: {torch.version.cuda if torch.cuda.is_available() else \"N/A\"}\")' && \
            python3 -c 'import torch; print(f\"GPU count: {torch.cuda.device_count() if torch.cuda.is_available() else 0}\")'
          "
    
    - name: Upload PyTorch wheel as artifact
      uses: actions/upload-artifact@v4
      with:
        name: pytorch-${{ inputs.pytorch_version || '2.8.0' }}-cu121-${{ matrix.gpu_type }}
        path: output/torch-*.whl
        retention-days: 30
    
    - name: Generate wheel info
      run: |
        # 生成wheel信息文件
        cat > output/pytorch-${{ inputs.pytorch_version || '2.8.0' }}-info.txt << EOF
        PyTorch Build Information
        ========================
        Version: ${{ inputs.pytorch_version || '2.8.0' }}
        CUDA Version: 12.1.1
        Python Version: 3.12
        GPU Architecture: ${{ matrix.cuda_arch }}
        Target GPU: ${{ matrix.gpu_type }}
        Build Date: $(date -u +"%Y-%m-%d %H:%M:%S UTC")
        Commit SHA: ${{ github.sha }}
        Runner: ${{ runner.name }}
        
        Files:
        $(ls -la output/torch-*.whl)
        
        Wheel Details:
        $(python3 -m pip show $(ls output/torch-*.whl | head -1) 2>/dev/null || echo "Wheel info not available")
        EOF
    
    - name: Upload build info
      uses: actions/upload-artifact@v4
      with:
        name: pytorch-${{ inputs.pytorch_version || '2.8.0' }}-buildinfo-${{ matrix.gpu_type }}
        path: output/pytorch-*-info.txt
        retention-days: 30

  create-release:
    if: github.event_name == 'workflow_dispatch' || startsWith(github.ref, 'refs/tags/')
    needs: build-pytorch
    runs-on: ubuntu-latest
    permissions:
      contents: write
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    
    - name: Download all artifacts
      uses: actions/download-artifact@v4
      with:
        path: artifacts/
    
    - name: Prepare release files
      run: |
        mkdir -p release/
        
        # 收集所有wheel文件
        find artifacts/ -name "torch-*.whl" -exec cp {} release/ \;
        
        # 收集构建信息
        find artifacts/ -name "*-info.txt" -exec cp {} release/ \;
        
        # 创建release说明
        cat > release/RELEASE_NOTES.md << EOF
        # PyTorch ${{ inputs.pytorch_version || '2.8.0' }} for CUDA 12.1
        
        ## 构建信息
        - **PyTorch版本**: ${{ inputs.pytorch_version || '2.8.0' }}
        - **CUDA版本**: 12.1.1
        - **Python版本**: 3.12
        - **支持GPU**: RTX 3090Ti, A100, A800, H20
        - **构建日期**: $(date -u +"%Y-%m-%d")
        
        ## 安装方法
        
        \`\`\`bash
        # 下载对应GPU的wheel文件
        pip install torch-${{ inputs.pytorch_version || '2.8.0' }}*.whl
        \`\`\`
        
        ## 验证安装
        
        \`\`\`python
        import torch
        print(f"PyTorch version: {torch.__version__}")
        print(f"CUDA available: {torch.cuda.is_available()}")
        print(f"CUDA version: {torch.version.cuda}")
        \`\`\`
        
        ## 文件说明
        
        $(ls -la release/)
        EOF
        
        echo "Release files prepared:"
        ls -la release/
    
    - name: Create Release
      uses: softprops/action-gh-release@v1
      with:
        tag_name: pytorch-${{ inputs.pytorch_version || '2.8.0' }}-${{ github.run_number }}
        name: PyTorch ${{ inputs.pytorch_version || '2.8.0' }} for CUDA 12.1
        body_path: release/RELEASE_NOTES.md
        files: release/*
        draft: false
        prerelease: false
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
